##### 方法

留出一定比例的数据作为测试集。在剩余的数据上训练模型，然后在测试集上评估模型

![1554801162950](C:\Users\26910\AppData\Roaming\Typora\typora-user-images\1554801162950.png)

##### 代码

```python
num_validation_samples = 10000

#通常需要打乱数据
np.random.shuffle(data) 

#定义验证集
validation_data = data[:num_validation_samples] 
data = data[num_validation_samples:]

#定义训练集
training_data = data[:] 

#在训练数据上训练模型，并在验证数据上评估模型
model = get_model() 
model.train(training_data)
validation_score = model.evaluate(validation_data)

# 现在你可以调节模型、重新训练、评估，然后再次调节……
model = get_model() 
model.train(np.concatenate([training_data,
 validation_data]))
test_score = model.evaluate(test_data)
```

缺点：如果可用的数据很少，那么可能验证集和测试集包含的样本就太少，从而无法在统计学上代表数据。

原因：如果在划分数据前进行不同的随机打乱，最终得到的模型性能差别很大，那么就存在这个问题。

